{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install Dependencies\n",
    "=============\n",
    "pip install pandas matplotlib numpy jupter openpyxl nltk gensim pyLDAvis\n",
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/neerajkumar/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/neerajkumar/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>author</th>\n",
       "      <th>publicationTime</th>\n",
       "      <th>bodyText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.209799e+09</td>\n",
       "      <td>10/02/2016 10:30</td>\n",
       "      <td>RT @350Australia: Adani Group's Aust #coal min...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.209799e+09</td>\n",
       "      <td>10/02/2016 10:36</td>\n",
       "      <td>RT @avivaimhof: Poor old #coal. Now even #Viet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4.306011e+07</td>\n",
       "      <td>10/02/2016 10:37</td>\n",
       "      <td>RT @market_forces: Funds have burned billions ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2.209799e+09</td>\n",
       "      <td>10/02/2016 10:37</td>\n",
       "      <td>RT @avivaimhof: #Vietnam PM Announces Retreat ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5.855606e+08</td>\n",
       "      <td>10/02/2016 10:41</td>\n",
       "      <td>RT @350Australia: Adani Group's Aust #coal min...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0        author   publicationTime  \\\n",
       "0          0  2.209799e+09  10/02/2016 10:30   \n",
       "1          1  2.209799e+09  10/02/2016 10:36   \n",
       "2          2  4.306011e+07  10/02/2016 10:37   \n",
       "3          3  2.209799e+09  10/02/2016 10:37   \n",
       "4          4  5.855606e+08  10/02/2016 10:41   \n",
       "\n",
       "                                            bodyText  \n",
       "0  RT @350Australia: Adani Group's Aust #coal min...  \n",
       "1  RT @avivaimhof: Poor old #coal. Now even #Viet...  \n",
       "2  RT @market_forces: Funds have burned billions ...  \n",
       "3  RT @avivaimhof: #Vietnam PM Announces Retreat ...  \n",
       "4  RT @350Australia: Adani Group's Aust #coal min...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing require library\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "import datetime\n",
    "import time\n",
    "import datetime\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from tensor_lda.tensor_lda import TensorLDA\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pyLDAvis.gensim\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import plot\n",
    "# downloading component of nltk \n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "\n",
    "# Loading csv data file\n",
    "df = pd.read_csv('data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string datetime into python datetime object\n",
    "df[\"publicationTime\"] = pd.to_datetime(df[\"publicationTime\"],  format='%d/%m/%Y %H:%M')\n",
    "df['bodyText'].fillna('not found',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a date in DD-MM-YYYY format and user single quote like: '10-02-2016''10-02-2016'\n"
     ]
    }
   ],
   "source": [
    "# Enter date and should enter format DD-MM-YYYY and when you enter using single quote both side on date\n",
    "# Example: '10-02-2016' \n",
    "date_entry = input(\"Enter a date in DD-MM-YYYY format and user single quote like: '10-02-2016'\")\n",
    "day, month, year = map(int, date_entry.split('-'))\n",
    "date = datetime.date(year, month, day)\n",
    "if not (df.iloc[0]['publicationTime'].date() <= date and df.iloc[-1]['publicationTime'].date() >= date):\n",
    "    raise Exception(\"Error: Date should be between tweets data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Interval in seconds : 300\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>author</th>\n",
       "      <th>publicationTime</th>\n",
       "      <th>bodyText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.209799e+09</td>\n",
       "      <td>2016-02-10 10:30:00</td>\n",
       "      <td>RT @350Australia: Adani Group's Aust #coal min...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.209799e+09</td>\n",
       "      <td>2016-02-10 10:36:00</td>\n",
       "      <td>RT @avivaimhof: Poor old #coal. Now even #Viet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4.306011e+07</td>\n",
       "      <td>2016-02-10 10:37:00</td>\n",
       "      <td>RT @market_forces: Funds have burned billions ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2.209799e+09</td>\n",
       "      <td>2016-02-10 10:37:00</td>\n",
       "      <td>RT @avivaimhof: #Vietnam PM Announces Retreat ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5.855606e+08</td>\n",
       "      <td>2016-02-10 10:41:00</td>\n",
       "      <td>RT @350Australia: Adani Group's Aust #coal min...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0        author     publicationTime  \\\n",
       "0          0  2.209799e+09 2016-02-10 10:30:00   \n",
       "1          1  2.209799e+09 2016-02-10 10:36:00   \n",
       "2          2  4.306011e+07 2016-02-10 10:37:00   \n",
       "3          3  2.209799e+09 2016-02-10 10:37:00   \n",
       "4          4  5.855606e+08 2016-02-10 10:41:00   \n",
       "\n",
       "                                            bodyText  \n",
       "0  RT @350Australia: Adani Group's Aust #coal min...  \n",
       "1  RT @avivaimhof: Poor old #coal. Now even #Viet...  \n",
       "2  RT @market_forces: Funds have burned billions ...  \n",
       "3  RT @avivaimhof: #Vietnam PM Announces Retreat ...  \n",
       "4  RT @350Australia: Adani Group's Aust #coal min...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Enter Interval in seconds that will show each interval related data\n",
    "interval = input('Enter Interval in seconds : ')\n",
    "dateslot_df = df.loc[df['publicationTime'].apply(lambda x: x.date()) == date]\n",
    "dateslot_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating new DataFrame of custom data data store count of tweet, users, and number of tweets\n",
    "users = []\n",
    "combine_data = []\n",
    "counter  = 0\n",
    "tweet_time = 0\n",
    "old_timestamp = 0\n",
    "row_count = 0\n",
    "df_tweet = pd.DataFrame()\n",
    "tweet_list = []\n",
    "index_counter = 0\n",
    "def filter_data(text, combine_data):\n",
    "    for t in text.split(' '):\n",
    "        if t.startswith('@'):\n",
    "            combine_data.append(t)\n",
    "    return combine_data\n",
    "\n",
    "def filter_retweet(text, count):\n",
    "    for index, t in enumerate(text.split(' ')):\n",
    "        if index == 0 and t == 'RT':\n",
    "            count += 1\n",
    "    return count  \n",
    "for i, row in dateslot_df.iterrows():\n",
    "    is_exist = pd.isnull(row['publicationTime'])\n",
    "    if not is_exist:\n",
    "        timestamp = time.mktime(row['publicationTime'].timetuple())\n",
    "        if i == 0:\n",
    "            old_timestamp = timestamp\n",
    "        if tweet_time > old_timestamp + float(interval):\n",
    "            diff = (tweet_time - old_timestamp + float(interval))/float(interval)\n",
    "            for d in range(1,int(diff)):\n",
    "                index_counter += 1\n",
    "                old_timestamp = old_timestamp+(float(interval*1)) \n",
    "                pub = datetime.datetime.fromtimestamp(old_timestamp).strftime('%Y-%m-%d %H:%M:%S')\n",
    "                temp = pd.DataFrame({'publicationTime': pub, 'users': len(set(combine_data)), 'retweet': counter,'count': row_count, 'tweets': str(tweet_list)},index=[index_counter])\n",
    "                df_tweet = pd.concat([df_tweet, temp])\n",
    "            combine_data = []\n",
    "            tweet_list = []\n",
    "            counter = 0\n",
    "            row_count = 0\n",
    "        else:\n",
    "            combine_data = filter_data(row['bodyText'], combine_data)\n",
    "            counter = filter_retweet(row['bodyText'], counter)\n",
    "            tweet_time = timestamp\n",
    "            tweet_list.append(row['bodyText'])\n",
    "            row_count += 1\n",
    "df_tweet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting value of action that will help to show graph of that data\n",
    "column_dict = {1:'users', 2:'count',3:'retweet'}\n",
    "action = int(input('1 for users, 2 for tweets count, 3 for retweets: '))\n",
    "data = [go.Bar(x=df_tweet['publicationTime'],y=df_tweet[column_dict[action]])]\n",
    "plot(data)\n",
    "# for showing bar graph using matplotlib\n",
    "# plt.bar(df_tweet['publicationTime'], df_tweet[column_dict[action]], align='center')\n",
    "# plt.title('Interval')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Velocity\n",
    "velocity = df_tweet['count'].sum() / float(df_tweet.shape[0]*interval) \n",
    "print \"Velocity: {} tweets/second\".format(velocity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_window(df):\n",
    "    window = []\n",
    "    count = 1\n",
    "    for i, row in df.iterrows():\n",
    "        window.append(\"Window {}\".format(count))\n",
    "        count += 1\n",
    "    return window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving specific interval tweets in csv file\n",
    "df_tweet['window'] = gen_window(df_tweet)\n",
    "df_tweet.to_csv('output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter Windows number that should be integer and should be present in \n",
    "window = input('Enter Windows number : ')\n",
    "row = df_tweet.loc[df_tweet['window'] == 'Window {0}'.format(window)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving all data into xlsx \n",
    "data = pd.DataFrame()\n",
    "tweet_list = []\n",
    "for index, r in enumerate(eval(row.iloc[0]['tweets'])):\n",
    "    temp = pd.DataFrame({'tweet':str(r)},index=[index])\n",
    "    tweet_list.append(r)\n",
    "    data = pd.concat([data, temp])\n",
    "writer = pd.ExcelWriter('output.xlsx')\n",
    "data.to_excel(writer,'Sheet1')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing task of word analysis using nltk\n",
    "stop = set(stopwords.words('english'))\n",
    "exclude = set(string.punctuation) \n",
    "lemma = WordNetLemmatizer()\n",
    "def clean(doc):\n",
    "    stop_free = \" \".join([i for i in doc.lower().split() if i not in stop])\n",
    "    punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\n",
    "    normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
    "    return normalized\n",
    "doc_clean = [clean(doc).split() for doc in tweet_list]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model\n",
      "\n",
      "Topics in LDA model:\n",
      "Topic #0 (prior: 0.000): strike project pm industry solar new agchatoz dollars funds market_forces\n",
      "Topic #1 (prior: 0.000): nswpol rt water climate lateline angels lockthegate cockroaches newhope action\n",
      "Topic #2 (prior: 0.000): coal nswpol water lng greg maxphillips beat csg gets decision\n",
      "Topic #3 (prior: 0.000): global mikebairdmp power liverpoolplains china santos gas pollution placed amp\n",
      "Topic #4 (prior: 0.000): csgo mikebairdmp power china rt super amp won qldpol l_deweaver\n",
      "Topic #5 (prior: 0.001): shenhua new fracking qldpol ask future gas adani greghuntmp adropex\n",
      "Topic #6 (prior: 0.001): csgo strike global super voters dirty coal btecpsxd3v placed fossilfuels\n",
      "Topic #7 (prior: 0.001): rt auspol shenhua australisterry stopshenhua greg lateline landholders beat newhope\n",
      "Topic #8 (prior: 0.001): new strike head mikebairdmp mining amp climate won nswpol china\n",
      "Topic #9 (prior: 0.001): water greghuntmp nswpol power unconventional unmitigated disaster stopshenhua stop liverpoolplains\n",
      "Topic #10 (prior: 0.001): http rt stop coal need lockthegate don fracking lng gets\n",
      "Topic #11 (prior: 0.001): coal auspol new liverpoolplains power strike shows solar australia pollution\n",
      "Topic #12 (prior: 0.002): study impacts dangerous urgent auspol nhmrc petition csg calling health\n",
      "Topic #13 (prior: 0.002): rt coal ikrhzphy7q ko1rp5llqs mining troubles far group aust greg\n",
      "Topic #14 (prior: 0.002): liverpoolplains head power climate angels nswpol maxphillips lateline pilliga future\n",
      "Topic #15 (prior: 0.002): coal nswpol rt new strike power auspol lng liverpoolplains amp\n",
      "Topic #16 (prior: 0.002): coal pollution unbelievable tourism sustainable lot killing know l_deweaver rt\n",
      "Topic #17 (prior: 0.002): investment rt fossilfuels coal super market_forces btecpsxd3v funds dirty dollars\n",
      "Topic #18 (prior: 0.003): troygrant stopshenhua revolution think ll shenhua auspol rt people mikebairdmp\n",
      "Topic #19 (prior: 0.002): coal auspol qldpol mining qgzfo4quee kellyoshanassy lobby carmichael concedes qld\n",
      "Topic #20 (prior: 0.003): australisterry stopshenhua new water conditions pilliga mikebairdmp china barnaby_joyce won\n",
      "Topic #21 (prior: 0.003): greghuntmp australia qldpol new disguise disastrous decision greg fracking oil\n",
      "Topic #22 (prior: 0.003): mining placed liverpoolplains lateline gets newhope santos shows unconventional climate\n",
      "Topic #23 (prior: 0.003): angels health head strike shenhua don qld future world climateangels\n",
      "Topic #24 (prior: 0.002): climate arms solar gets ko1rp5llqs ikrhzphy7q far troubles lng head\n",
      "Topic #25 (prior: 0.003): auspol coal csg springst vicfarmers seam lakesoil mystery theage gas\n",
      "Topic #26 (prior: 0.003): rt pilliga csg protect climateangels generation auspol future duty pilligapush\n",
      "Topic #27 (prior: 0.003): yug70oac2w shenhua pm got oppose lpp auspol coal chance phil_laird1\n",
      "Topic #28 (prior: 0.003): scuttle shenhua littleblackrock handouts kh7l5dya auspol rt australisterry ask cockroaches\n",
      "Topic #29 (prior: 0.003): greg head coal water pilligapush mikebairdmp strike santos stop world\n",
      "Topic #30 (prior: 0.003): shenhua coal csgo strike adropex duty lng ask climateangels santos\n",
      "Topic #31 (prior: 0.003): csg nswpol rt pilligapush santos angels climate water coal auspol\n",
      "Topic #32 (prior: 0.004): won wash auspol voters stopshenhua tonyhwindsor peterjameswills xpxoz shenhua rt\n",
      "Topic #33 (prior: 0.004): strike new water china shenhua protect billion brink beat cockroaches\n",
      "Topic #34 (prior: 0.005): liverpoolplains csgo australisterry fracking water power shows people ahead aware\n",
      "Topic #35 (prior: 0.005): shenhua auspol head rt australisterry nswpol maxphillips climate angels mining\n",
      "Topic #36 (prior: 0.005): greghuntmp stopshenhua shenhua disguise disastrous decision auspol placed rt beat\n",
      "Topic #37 (prior: 0.005): csg angels climate greg http new cockroaches gets unconventional water\n",
      "Topic #38 (prior: 0.005): nswpol greg oil ask world pilliga mikebairdmp lockthegate lateline fracking\n",
      "Topic #39 (prior: 0.005): shenhua newhope auspol australisterry mining australia landholders rt inappropriate arms\n",
      "()\n",
      "[6.40068046e-06 1.17815925e-05 2.34409618e-05 2.88482247e-05\n",
      " 4.39458160e-05 4.86421133e-05 8.40536163e-05 9.60103397e-05\n",
      " 1.10864791e-04 1.16287447e-04 1.21787818e-04 9.14019619e-02\n",
      " 1.56627867e-04 8.99913521e-01 1.59853643e-04 1.98321785e-04\n",
      " 2.08373198e-04 2.25008789e-04 2.27065820e-04 2.17891670e-04\n",
      " 2.57700692e-04 2.69393605e-04 2.67370645e-04 2.47778235e-04\n",
      " 1.80598086e-04 2.70794707e-04 2.71608190e-04 2.87358462e-04\n",
      " 2.90825447e-04 2.85542200e-04 3.08019851e-04 3.07204670e-04\n",
      " 3.21205578e-04 3.28607327e-04 4.28749437e-04 4.12589746e-04\n",
      " 4.35849513e-04 4.63745100e-04 4.75975221e-04 4.88394712e-04]\n"
     ]
    }
   ],
   "source": [
    "# Tensor LDA model based analysis.\n",
    "tweet_list = dateslot_df['bodyText'].tolist()\n",
    "n_features = 1000\n",
    "n_components = 40\n",
    "n_top_words = 10\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        topic_prior = model.alpha_[topic_idx]\n",
    "        message = \"Topic #%d (prior: %.3f): \" % (topic_idx, topic_prior)\n",
    "        message += \" \".join([feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "tf_vectorizer = CountVectorizer(max_df=0.8, min_df=5, max_features=n_features, stop_words='english')\n",
    "tf = tf_vectorizer.fit_transform(tweet_list)\n",
    "lda = TensorLDA(n_components=n_components, alpha0=.1)\n",
    "print(\"Fitting model\")\n",
    "lda.fit(tf)\n",
    "print(\"\\nTopics in LDA model:\")\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "print_top_words(lda, tf_feature_names, n_top_words)\n",
    "doc_topics = lda.transform(tf[0:2, :])\n",
    "print(doc_topics[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the object for LDA model using gensim library\n",
    "dictionary = corpora.Dictionary(doc_clean)\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean]\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "ldamodel = Lda(doc_term_matrix, num_topics=row.iloc[0]['count'], id2word = dictionary, passes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing all data of LDA model\n",
    "ldamodel.print_topics(num_topics=row.iloc[0]['count'], num_words=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing visualization of LDA model\n",
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.gensim.prepare(ldamodel, doc_term_matrix, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

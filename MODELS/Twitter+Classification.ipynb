{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import json \n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import time\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.mllib.feature import HashingTF\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.classification import NaiveBayes\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.mllib.util import MLUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "#global variables for the tokenize function \n",
    "PUNCTUATION = set(string.punctuation)\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "STEMMER = PorterStemmer()\n",
    "LEMMER = WordNetLemmatizer()\n",
    "tweet_tokenizer = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "htf = HashingTF(50000) #vectorize the hash with 50k features. Determines the size of a sparse vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GSR Records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load GSR records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load gsr web article data in json format\n",
    "def load_gsr_articles():\n",
    "    #raw_data = sc.textFile(\"hdfs:///gsr.json\") #includes months data \n",
    "    raw_data = sc.textFile(\"hdfs:///gsr3.json\") #only english\n",
    "    data = raw_data.map(lambda line: json.loads(line))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following sampling methods were done to balance the population groups\n",
    "If the population is balance there is no need of a sampling method. Data can be identified as labels and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The articles should be balanced for populations. \n",
    "#This function will up-sample the minority in gsr3 records. Where \"general\" and \"labor\" are a majority.\n",
    "#minorityFraction was calculated using number of articles for 'labour' and 'education'.\n",
    "#Becaues 'labour' has the lowest frequency in majority classes and 'education' has the highest of the minority classes\n",
    "#This fraction will not oversample the minority class (similar case for down-sampling)\n",
    "def upsample_minority(df):\n",
    "    \n",
    "    #Identify the labels and content for articles. \n",
    "    data_pared = df.map(lambda line: {'populationGroup': line['populationGroup'], 'article': line['article']})\n",
    "    \n",
    "    labour_class = data_pared.filter(lambda line: 'lab' in line['populationGroup'].lower()).count()\n",
    "    edu_class = data_pared.filter(lambda line: 'education' in line['populationGroup'].lower()).count()\n",
    "    \n",
    "    minorityFraction = labour_class / float(edu_class)\n",
    "\n",
    "    genaralSample = data_pared.filter(lambda line: 'general' in line['populationGroup'].lower())\n",
    "    labourSample = data_pared.filter(lambda line: 'lab' in line['populationGroup'].lower())\n",
    "    MajoritySample = genaralSample.union(labourSample)\n",
    "\n",
    "    MinoritySample = data_pared.filter(lambda line: 'general' not in line['populationGroup'].lower())\\\n",
    "    .filter(lambda line: 'lab' not in line['populationGroup'].lower()).sample(withReplacement=True, fraction=minorityFraction)\n",
    "\n",
    "    balancedData = MajoritySample.union(MinoritySample)\n",
    "    return balancedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#down sampling\n",
    "#This function will down-sample the majority in gsr3 records. Where \"general\" and \"labor\" are a majority.\n",
    "def downsample_majority(df):\n",
    "    \n",
    "    data_pared = df.map(lambda line: {'populationGroup': line['populationGroup'], 'article': line['article']})\n",
    "    \n",
    "    labour_class = data_pared.filter(lambda line: 'lab' in line['populationGroup'].lower()).count()\n",
    "    edu_class = data_pared.filter(lambda line: 'education' in line['populationGroup'].lower()).count()\n",
    "    \n",
    "    majorityFraction = float(edu_class)/labour_class \n",
    "\n",
    "    genaralSample = data_pared.filter(lambda line: 'general' in line['populationGroup'].lower())\\\n",
    "                            .sample(withReplacement=True, fraction=majorityFraction)\n",
    "    labourSample = data_pared.filter(lambda line: 'lab' in line['populationGroup'].lower())\\\n",
    "                            .sample(withReplacement=True, fraction=majorityFraction)\n",
    "        \n",
    "    MajoritySample = genaralSample.union(labourSample)\n",
    "\n",
    "    MinoritySample = data_pared.filter(lambda line: 'general' not in line['populationGroup'].lower())\\\n",
    "    .filter(lambda line: 'lab' not in line['populationGroup'].lower())\n",
    "\n",
    "    balancedData = MajoritySample.union(MinoritySample)\n",
    "\n",
    "    return balancedData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize content to a bag of words, extract features. And label population groups neumerically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to break text into \"tokens\", lowercase them, remove punctuation and stopwords, and lemmatize\n",
    "def tokenize(text):\n",
    "    #load nltk dictionaries to cluster. temporary \n",
    "    nltk.data.path.append(\"/local/hdfs-volume/data/nltk_data\")\n",
    "    \n",
    "    tokens = word_tokenize(text)\n",
    "    lowercased = [t.lower() for t in tokens]\n",
    "    no_punctuation = []\n",
    "    for word in lowercased:\n",
    "        punct_removed = ''.join([letter for letter in word if not letter in PUNCTUATION and not letter.isdigit()])\n",
    "        no_punctuation.append(punct_removed)\n",
    "    no_stopwords = [w for w in no_punctuation if not w in STOPWORDS]\n",
    "    #stemmed = [STEMMER.stem(w) for w in no_stopwords]\n",
    "    stemmed = [LEMMER.lemmatize(w) for w in no_stopwords]\n",
    "    return [w for w in stemmed if w]\n",
    "\n",
    "\n",
    "#label classes for Naive Bayse considering multiple targets\n",
    "#all population groups should be converted to a numeric format to generate the sparce vector\n",
    "#therefore, the 10 poppulation group were assigned with a number 1-10\n",
    "def lable_classes(pop_item):\n",
    "    #population = pop_item.lower()\n",
    "    if \"education\" in pop_item.lower():\n",
    "        pop_item = 1\n",
    "    elif \"general\" in pop_item.lower():\n",
    "        pop_item = 2\n",
    "    elif \"legal\" in pop_item.lower():\n",
    "        pop_item = 3\n",
    "    elif re.compile('bus[iness|siness]').match(pop_item.lower()):\n",
    "        pop_item = 4\n",
    "    elif re.compile('eth[nic|ic]').match(pop_item.lower()):\n",
    "        pop_item = 5\n",
    "    elif \"medical\" in pop_item.lower():\n",
    "        pop_item = 6  \n",
    "    elif \"religious\" in pop_item.lower():\n",
    "        pop_item = 7  \n",
    "    elif re.compile('agricul[tural|ture]').match(pop_item.lower()):\n",
    "        pop_item = 8\n",
    "    elif re.compile('lab[or|our]').match(pop_item.lower()):\n",
    "        pop_item = 9\n",
    "    elif \"media\" in pop_item.lower():\n",
    "        pop_item = 10\n",
    "    return pop_item\n",
    "\n",
    "\n",
    "\n",
    "#extract intrested features from article content for population group\n",
    "#input: gsr article data in json format\n",
    "#output: population group and article content\n",
    "def tokenize_articles(data_paired):\n",
    "    \n",
    "    data_cleaned = data_paired.map(lambda pared_line: {'populationGroup': lable_classes(pared_line['populationGroup']),'article':tokenize(pared_line['article'])})\n",
    "    return data_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Twitter feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#extract meaningful words as features from twitter\n",
    "def feature_extraction(tokens):\n",
    "    nltk.data.path.append(\"/local/hdfs-volume/data/nltk_data\")\n",
    "    \n",
    "    lowercased = [t.lower() for t in tokens]\n",
    "    no_punctuation = []\n",
    "    for word in lowercased:\n",
    "        punct_removed = ''.join([letter for letter in word if not letter in PUNCTUATION and not letter.isdigit()])\n",
    "        no_punctuation.append(punct_removed)\n",
    "    no_stopwords = [w for w in no_punctuation if not w in STOPWORDS]\n",
    "    #stemmed = [STEMMER.stem(w) for w in no_stopwords]\n",
    "    stemmed = [LEMMER.lemmatize(w) for w in no_stopwords]\n",
    "    no_links = [w for w in stemmed if (not 'http' in w) and len(w)>2]\n",
    "    return [w for w in no_links if w]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Twitter Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_tweets(tweets_data_path):\n",
    "    \n",
    "    tweets_data = []\n",
    "    tweets_file = open(tweets_data_path, \"r\")\n",
    "    for line in tweets_file:\n",
    "        try:\n",
    "            tweet = json.loads(line)\n",
    "            #print(tweet['text'])\n",
    "            tweets_data.append(tweet)\n",
    "        except:\n",
    "            continue\n",
    "    return tweets_data\n",
    "\n",
    "\n",
    "\n",
    "#load labeled tweets\n",
    "business_data = sc.parallelize(load_tweets(\"Tweets_NB/business_tweet.txt\"))\n",
    "agri_data = sc.parallelize(load_tweets(\"Tweets_NB/agri_tweet.txt\"))\n",
    "edu_data = sc.parallelize(load_tweets(\"Tweets_NB/education_tweet.txt\"))\n",
    "ethic_data = sc.parallelize(load_tweets(\"Tweets_NB/ethic_tweet.txt\"))\n",
    "labour_data = sc.parallelize(load_tweets(\"Tweets_NB/labour_tweet.txt\"))\n",
    "medical_data = sc.parallelize(load_tweets(\"Tweets_NB/medical_tweet.txt\"))\n",
    "religious_data = sc.parallelize(load_tweets(\"Tweets_NB/religious_tweet.txt\"))\n",
    "general_data = sc.parallelize(load_tweets(\"Tweets_NB/general_tweet.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create a twitter dataset including labels and features for each tweet\n",
    "agri_features = agri_data.map(lambda row: row.get('text',None)).map(lambda line: tweet_tokenizer.tokenize(line))\\\n",
    ".map(lambda tokens: {\"article\":feature_extraction(tokens),\"populationGroup\":8})\n",
    "business_features = business_data.map(lambda row: row.get('text',None)).map(lambda line: tweet_tokenizer.tokenize(line))\\\n",
    ".map(lambda tokens: {\"article\":feature_extraction(tokens),\"populationGroup\":4})\n",
    "edu_features = edu_data.map(lambda row: row.get('text',None)).map(lambda line: tweet_tokenizer.tokenize(line))\\\n",
    ".map(lambda tokens: {\"article\":feature_extraction(tokens),\"populationGroup\":1})\n",
    "ethic_features = ethic_data.map(lambda row: row.get('text',None)).map(lambda line: tweet_tokenizer.tokenize(line))\\\n",
    ".map(lambda tokens: {\"article\":feature_extraction(tokens),\"populationGroup\":5})\n",
    "labour_features = labour_data.map(lambda row: row.get('text',None)).map(lambda line: tweet_tokenizer.tokenize(line))\\\n",
    ".map(lambda tokens: {\"article\":feature_extraction(tokens),\"populationGroup\":9})\n",
    "medical_features = medical_data.map(lambda row: row.get('text',None)).map(lambda line: tweet_tokenizer.tokenize(line))\\\n",
    ".map(lambda tokens: {\"article\":feature_extraction(tokens),\"populationGroup\":6})\n",
    "religious_features = religious_data.map(lambda row: row.get('text',None)).map(lambda line: tweet_tokenizer.tokenize(line))\\\n",
    ".map(lambda tokens: {\"article\":feature_extraction(tokens),\"populationGroup\":7})\n",
    "general_features = general_data.map(lambda row: row.get('text',None)).map(lambda line: tweet_tokenizer.tokenize(line))\\\n",
    ".map(lambda tokens: {\"article\":feature_extraction(tokens),\"populationGroup\":2})\n",
    "\n",
    "\n",
    "labeled_twitter_data = business_features.union(edu_features.union(ethic_features.union(labour_features.union(agri_features))))\n",
    "labeled_twitter_data  = labeled_twitter_data.union(general_features.union(medical_features.union(religious_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_twitter_data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#transform extracted features to a sparse vector (hashing)\n",
    "#input: rdd of label(population group) and features(extracted words) for each article or tweet \n",
    "def transform_data(data_cleaned):\n",
    "    #vectorize the hash with 50k features. Determines the size of a sparse vector\n",
    "    #htf = HashingTF(50000)\n",
    "    \n",
    "    data_hashed = data_cleaned.map(lambda dict_line: LabeledPoint(dict_line['populationGroup'], htf.transform(dict_line['article'])))\n",
    "    \n",
    "    return data_hashed    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(model_data):\n",
    "\n",
    "    model = NaiveBayes.train(model_data)\n",
    "    return model\n",
    "\n",
    "\n",
    "#inputs: train and test data (vector in label feture format)\n",
    "#output: returns a list of labels predicted for tweets  (population group predicted, default label) \n",
    "def predict_tweets(train_data, test_data):\n",
    "    \n",
    "    NB_model = train_model(train_data)\n",
    "    \n",
    "    prediction_and_label = test_data.map(lambda p : (float(NB_model.predict(p.features)), p.label))\n",
    "    \n",
    "    return prediction_and_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#obtain metrics based on model predictins\n",
    "#input: model output of list with predicted and initial label\n",
    "#output: metrics object\n",
    "def get_model_metrics(predict_and_label):\n",
    "    \n",
    "    return MulticlassMetrics(predict_and_label)\n",
    "\n",
    "\n",
    "#Obtain the confusion matrics in a array\n",
    "#input: metric object created from model output\n",
    "#output: confusion metrics\n",
    "def get_confusionMatrix(metrics):\n",
    "    \n",
    "    return metrics.confusionMatrix().toArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This function is to relabel the numeric class labels to user friendly format.\n",
    "#all labels were transformed to a numeric format to generate the sparse vector to get the hash\n",
    "def rename_label(label):\n",
    "    \n",
    "    if label==1:\n",
    "        label=\"education\"\n",
    "    elif label==2:\n",
    "        label=\"general\"\n",
    "    elif label==3:\n",
    "        label=\"legal\"\n",
    "    elif label==4:\n",
    "        label=\"business\"\n",
    "    elif label==5:\n",
    "        label=\"ethnic\"\n",
    "    elif label==6:\n",
    "        label=\"medical\"\n",
    "    elif label==7:\n",
    "        label=\"religious\"\n",
    "    elif label==8:\n",
    "        label=\"agricultural\"\n",
    "    elif label==9:\n",
    "        label=\"labour\"\n",
    "    elif label==10:\n",
    "        label=\"media\"\n",
    "        \n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def NaiveBayes_Model():\n",
    "    \n",
    "    data = load_gsr_articles()\n",
    "    data_paired = upsample_minority(data)\n",
    "    #data_paired = downsample_majority(data)\n",
    "    data_cleaned = tokenize_articles(data_paired)\n",
    "    \n",
    "    #### method 1 ####\n",
    "    #twitter_train_sample, twitter_test_sample = labeled_twitter_data.randomSplit([0.8,0.2])\n",
    "    #data_set = data_cleaned.union(twitter_train_sample) \n",
    "    #train_data = transform_data(data_set)\n",
    "    #test_data = transform_data(twitter_test_sample)\n",
    "    \n",
    "    #### method 2 ####\n",
    "    twitter_data = transform_data(labeled_twitter_data) #only tweets as taining and test set\n",
    "    train_data, test_data =  twitter_data.randomSplit([0.8, 0.2])\n",
    "    \n",
    "    \n",
    "    #### method 3 ####\n",
    "    #data_set = data_cleaned.union(labeled_twitter_data)   #combine gsr and tweets\n",
    "    #data_set_hashed = transform_data(data_set)\n",
    "        \n",
    "    #train_data, test_data = data_set_hashed.randomSplit([0.8, 0.2])    #split training and test data\n",
    "    \n",
    "    \n",
    "    \n",
    "    #### method 4 ####\n",
    "    #train_data=transform_data(data_cleaned)   #only gsr data as training set\n",
    "    #test_data = transform_data(labeled_twitter_data)   #only tweets as test set\n",
    "  \n",
    "      \n",
    "    ##################\n",
    "        \n",
    "    #apply hashed test and training data to the model\n",
    "    prediction_label = predict_tweets(train_data, test_data)\n",
    "    \n",
    "    metrics = get_model_metrics(prediction_label)\n",
    "    \n",
    "    confusion_matrix = get_confusionMatrix(metrics)\n",
    "    print(confusion_matrix)\n",
    "\n",
    "    print(\"\\n Summary Statistics for the Overall Model \\n\")\n",
    "    accuracy = 1.0 * prediction_label.filter(lambda result_line: result_line[0] == result_line[1]).count() / test_data.count()\n",
    "    print(\"Accuracy of model = %0.2f\" %accuracy)\n",
    "    \n",
    "    precision = metrics.precision()\n",
    "    recall = metrics.recall()\n",
    "    f1Score = metrics.fMeasure()\n",
    "    print(\"Precision = %s\" % precision)\n",
    "    print(\"Recall = %s\" % recall)\n",
    "    print(\"F1 Score = %s\" % f1Score)   \n",
    "    \n",
    "    labels = test_data.map(lambda lp: lp.label).distinct().collect()\n",
    "    print(\"\\n Summary Statistics for Each Tested Class \\n\")\n",
    "    for label in sorted(labels):\n",
    "        print(\"Class %s precision = %s\" % (rename_label(label), metrics.precision(label)))\n",
    "        print(\"Class %s recall = %s\" % (rename_label(label), metrics.recall(label)))\n",
    "        print(\"Class %s F1 Measure = %s\" % (rename_label(label), metrics.fMeasure(label, beta=1.0)))\n",
    "        print(\"\\n\")\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_gsr_articles' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-be1557303af0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mNaiveBayes_Model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# gsr+twitter / twitter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-c5d23685597a>\u001b[0m in \u001b[0;36mNaiveBayes_Model\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mNaiveBayes_Model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_gsr_articles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mdata_paired\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupsample_minority\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#data_paired = downsample_majority(data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_gsr_articles' is not defined"
     ]
    }
   ],
   "source": [
    "NaiveBayes_Model() # gsr+twitter / twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_gsr_articles' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-2895dc3b3edc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mNaiveBayes_Model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#twitter/twitter (including general)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-c5d23685597a>\u001b[0m in \u001b[0;36mNaiveBayes_Model\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mNaiveBayes_Model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_gsr_articles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mdata_paired\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupsample_minority\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#data_paired = downsample_majority(data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_gsr_articles' is not defined"
     ]
    }
   ],
   "source": [
    "NaiveBayes_Model() #twitter/twitter (including general)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 18.   0.   0.   2.   2.   2.   0.   0.]\n",
      " [  0.   0.   1.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.  18.   1.   1.   0.   1.   2.]\n",
      " [  2.   0.   0.  18.   2.   0.   0.   0.]\n",
      " [  1.   0.   0.   1.  15.   0.   0.   0.]\n",
      " [  2.   0.   0.   2.   1.  15.   0.   1.]\n",
      " [  0.   0.   0.   0.   1.   0.  22.   1.]\n",
      " [  2.   0.   0.   1.   1.   0.   0.  15.]]\n",
      "\n",
      " Summary Statistics for the Overall Model \n",
      "\n",
      "Accuracy of model = 0.80\n",
      "Precision = 0.8013245033112583\n",
      "Recall = 0.8013245033112583\n",
      "F1 Score = 0.8013245033112583\n",
      "\n",
      " Summary Statistics for Each Tested Class \n",
      "\n",
      "Class education precision = 0.72\n",
      "Class education recall = 0.75\n",
      "Class education F1 Measure = 0.7346938775510204\n",
      "\n",
      "\n",
      "Class general precision = 0.0\n",
      "Class general recall = 0.0\n",
      "Class general F1 Measure = 0.0\n",
      "\n",
      "\n",
      "Class business precision = 0.9473684210526315\n",
      "Class business recall = 0.782608695652174\n",
      "Class business F1 Measure = 0.8571428571428571\n",
      "\n",
      "\n",
      "Class ethnic precision = 0.72\n",
      "Class ethnic recall = 0.8181818181818182\n",
      "Class ethnic F1 Measure = 0.7659574468085107\n",
      "\n",
      "\n",
      "Class medical precision = 0.6521739130434783\n",
      "Class medical recall = 0.8823529411764706\n",
      "Class medical F1 Measure = 0.75\n",
      "\n",
      "\n",
      "Class religious precision = 0.8823529411764706\n",
      "Class religious recall = 0.7142857142857143\n",
      "Class religious F1 Measure = 0.7894736842105262\n",
      "\n",
      "\n",
      "Class agricultural precision = 0.9565217391304348\n",
      "Class agricultural recall = 0.9166666666666666\n",
      "Class agricultural F1 Measure = 0.9361702127659574\n",
      "\n",
      "\n",
      "Class labour precision = 0.7894736842105263\n",
      "Class labour recall = 0.7894736842105263\n",
      "Class labour F1 Measure = 0.7894736842105263\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NaiveBayes_Model() #twitter/twitter (no general)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def NaiveBayes_Model04():\n",
    "    \n",
    "    data = load_gsr_articles()\n",
    "    data_paired = upsample_minority(data)\n",
    "    #data_paired = downsample_majority(data)\n",
    "    data_cleaned = tokenize_articles(data_paired)\n",
    "    \n",
    "    #### method 1 ####\n",
    "    #twitter_train_sample, twitter_test_sample = labeled_twitter_data.randomSplit([0.8,0.2])\n",
    "    #data_set = data_cleaned.union(twitter_train_sample) \n",
    "    #train_data = transform_data(data_set)\n",
    "    #test_data = transform_data(twitter_test_sample)\n",
    "    \n",
    "    #### method 2 ####\n",
    "    #twitter_data = transform_data(labeled_twitter_data) #only tweets as taining and test set\n",
    "    #train_data, test_data =  twitter_data.randomSplit([0.8, 0.2])\n",
    "    \n",
    "    \n",
    "    #### method 3 ####\n",
    "    data_set = data_cleaned.union(labeled_twitter_data)   #combine gsr and tweets\n",
    "    data_set_hashed = transform_data(data_set)\n",
    "        \n",
    "    train_data, test_data = data_set_hashed.randomSplit([0.8, 0.2])    #split training and test data\n",
    "\n",
    "      \n",
    "    ##################\n",
    "        \n",
    "    #apply hashed test and training data to the model\n",
    "    prediction_label = predict_tweets(train_data, test_data)\n",
    "    \n",
    "    metrics = get_model_metrics(prediction_label)\n",
    "    \n",
    "    confusion_matrix = get_confusionMatrix(metrics)\n",
    "    print(confusion_matrix)\n",
    "\n",
    "    print(\"\\n Summary Statistics for the Overall Model \\n\")\n",
    "    accuracy = 1.0 * prediction_label.filter(lambda result_line: result_line[0] == result_line[1]).count() / test_data.count()\n",
    "    print(\"Accuracy of model = %0.2f\" %accuracy)\n",
    "    \n",
    "    precision = metrics.precision()\n",
    "    recall = metrics.recall()\n",
    "    f1Score = metrics.fMeasure()\n",
    "    print(\"Precision = %s\" % precision)\n",
    "    print(\"Recall = %s\" % recall)\n",
    "    print(\"F1 Score = %s\" % f1Score)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 35.   5.   0.   5.   0.   0.   0.   0.]\n",
      " [  3.  12.   0.   0.   0.   0.   0.   0.]\n",
      " [  5.   1.  25.   1.   0.   1.   1.   2.]\n",
      " [  6.   8.   4.  18.   1.   1.   0.   2.]\n",
      " [  5.   4.   5.   0.  18.   1.   0.   2.]\n",
      " [  4.   4.   1.   0.   0.   9.   2.   0.]\n",
      " [  2.   1.   6.   1.   0.   0.  17.   1.]\n",
      " [  6.   5.   0.   0.   2.   0.   0.  28.]]\n",
      "\n",
      " Summary Statistics for the Overall Model \n",
      "\n",
      "Accuracy of model = 0.62\n",
      "Precision = 0.6230769230769231\n",
      "Recall = 0.6230769230769231\n",
      "F1 Score = 0.6230769230769231\n"
     ]
    }
   ],
   "source": [
    "NaiveBayes_Model04() #gsr+tweet/gsr+tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tweets for predictions using the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#class LoadTwitterData:\n",
    "    \n",
    "def get_data_bydate():\n",
    "    day = dt.datetime(2015,10,10)\n",
    "    day_ago = day - dt.timedelta(days=1)\n",
    "    \n",
    "    end_time = time.mktime(day.timetuple())\n",
    "    start_time = time.mktime(day_ago.timetuple())\n",
    "    \n",
    "    return sqlContext.read.load(format = \"au.com.d2dcrc.carbon.spark.tweets\", startTimestamp = int(start_time), endTimestamp = int(end_time))\n",
    "\n",
    "#returns tweets based on number of hours provided\n",
    "def get_twitter_data(hrs):\n",
    "    time_now = dt.datetime.now()\n",
    "    hour_ago = time_now - dt.timedelta(hours=hrs)\n",
    "    #print(time_now,hour_ago)\n",
    "\n",
    "    end_time = time.mktime(time_now.timetuple())\n",
    "    start_time = time.mktime(hour_ago.timetuple())\n",
    "    #print(start_time,end_time)\n",
    "    \n",
    "    return sqlContext.read.load(format = \"au.com.d2dcrc.carbon.spark.tweets\", startTimestamp = int(start_time), endTimestamp = int(end_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#extract english tweet text from loaded json data\n",
    "def extract_tweet_body(df):\n",
    "    \n",
    "    body_text = df.map(lambda row: row.data).map(lambda data: json.loads(data))\\\n",
    "    .filter(lambda line_tuple: 'en' in line_tuple['twitter_lang']).map(lambda line:line.get('body',None))\n",
    "    \n",
    "    return body_text   \n",
    "    \n",
    "    \n",
    "#preperation of label feature structure using tweet features, for sparse vector\n",
    "def extract_tweet_features(tweet_body):\n",
    "    \n",
    "    body_tokens = tweet_body.map(lambda line: tweet_tokenizer.tokenize(line)) #tokenize twitter text\n",
    "    #extract twitter features and assigne a default population label\n",
    "    twitter_features = body_tokens.map(lambda token_list: {\"article\":feature_extraction(token_list),\"populationGroup\":0}) \n",
    "   \n",
    "    return twitter_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#map labeled populations to text\n",
    "def _rename_label(item):\n",
    "    \n",
    "    if item[0]==1:\n",
    "        item[1]=\"education\"\n",
    "    elif item[0]==2:\n",
    "        item[1]=\"general\"\n",
    "    elif item[0]==3:\n",
    "        item[1]=\"legal\"\n",
    "    elif item[0]==4:\n",
    "        item[1]=\"business\"\n",
    "    elif item[0]==5:\n",
    "        item[1]=\"ethnic\"\n",
    "    elif item[0]==6:\n",
    "        item[1]=\"medical\"\n",
    "    elif item[0]==7:\n",
    "        item[1]=\"religious\"\n",
    "    elif item[0]==8:\n",
    "        item[1]=\"agricultural\"\n",
    "    elif item[0]==9:\n",
    "        item[1]=\"labour\"\n",
    "    elif item[0]==10:\n",
    "        item[1]=\"media\"\n",
    "        \n",
    "    return item\n",
    "\n",
    "\n",
    "#format predicted labels (population groups) to text\n",
    "def get_predictions(predictions):\n",
    "    answer = predictions.map(lambda l: _rename_label(list(l))).map(lambda x: x[1])\n",
    "    #answer = predictions.map(lambda l: _rename_label(list(l))).map(lambda x: tuple(x))#.zipWithIndex().map(lambda tuple_set: (tuple_set[1],tuple_set[0]))\n",
    "    return answer\n",
    "\n",
    "def display(tweet_body,indexed_answer):\n",
    "    return tweet_body.zip(indexed_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Predict_tweets_main():\n",
    "    \n",
    "    data = load_gsr_articles()\n",
    "    data_paired = upsample_minority(data)\n",
    "    data_cleaned = tokenize_articles(data_paired)\n",
    "    \n",
    "    #### method 1 ####\n",
    "    #predict tweets on model created with gasr + labeled tweets\n",
    "    data_set = data_cleaned.union(labeled_twitter_data)   #combine gsr and labeled tweets\n",
    "    train_data = transform_data(data_set)\n",
    "    \n",
    "    #### method 2 ####\n",
    "    #### predict tweets on model created with twitter data\n",
    "    #train_data = transform_data(labeled_twitter_data)\n",
    "    \n",
    "    df = get_twitter_data(1) #load tweets within past hour\n",
    "    tweet_body = extract_tweet_body(df)\n",
    "    twitter_data = extract_tweet_features(tweet_body)\n",
    "    \n",
    "    test_data = transform_data(twitter_data)\n",
    "    \n",
    "    predictions = predict_tweets(train_data, test_data)\n",
    "    indexed_answer = get_predictions(predictions)\n",
    "\n",
    "    joined_ans = display(tweet_body,indexed_answer)\n",
    "    print(joined_ans.take(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('RT @smoshanthony: I voted for @mielmonster in the #ShortyAwards because she brings abundant happiness and laughter: https://t.co/UaC90gdazE', 'general'), ('RT @MaitlandBusines: Chamber Chat: Chamber season  kicks off with a big 2016 planned https://t.co/XP8OkNZWrs via @maitlandmercury', 'labour'), ('@TairyGreene01 that sounds to liberal for me.', 'agricultural'), ('LISTEN: @SenBrettMason has an #EqualityCalling msg from QLD: https://t.co/hMKMfYYB1j | Supporters call: 1300663679', 'business'), ('TWENTY WAN https://t.co/BoWAm4dE2a', 'medical'), ('RT @Andrew_Nelson9: Bendigo man Daniel Reimers has pleaded guilty to 28 charges. Case moves to County Court next month. @9NewsMelb https://…', 'legal'), (\"RT @MicroSFF: Worried about Skynet's killer drones, he looked up 'how not be tagged as extremist' on the dark web.\\nFirst tip was 'Stay off …\", 'legal'), ('\"Would a Federal VET funding system be good for TAFE?\" by @paul_learning on @LinkedIn https://t.co/xRzGNV3Loz', 'legal'), ('@jonkudelka A lot of conservative commentators would get their feelings hurt...Will no-one think of the commentators???', 'legal'), ('@danielsahyounie @akabizzle lol sureeee fake messinator', 'religious'), ('Ur not a threat to me💯🔪', 'medical'), ('RT @rahulroushan: Cretins who\\'d label anyone \"bigot\" and \"communal\" for disagreement, are now saying that labeling people \"anti-national\" i…', 'legal'), (\"ok I've got a plan and I'm gonna stick to it\", 'education'), (\"RT @BONNIELYNN2015: Downtown Los Angeles I'm heading your way big love from Bonnie Lynn\", 'legal'), ('RT @BONNIELYNN2015: Big thanks to Palm Springs love you baby', 'legal'), ('Unfortunately, far too often, the idea of the Republic is disregarded for the idea of democracy.  https://t.co/NED01mOFI7', 'labour'), ('It was awesome to meet Dale Morris, Toby McLean, Joel Hamling, Bailey Dale and Bailey Williams… https://t.co/ZoxXjUZCRW', 'business'), ('pancakes at 1 am 😁', 'ethnic'), ('RT @dfg77: Sheehan has really hit gold here. #buythepaper https://t.co/fhxQf14OGA', 'labour'), (\"On Might and Dissent - Is India Hilter's best student? \\nhttps://t.co/uBsSd9AnRa\", 'education')]\n"
     ]
    }
   ],
   "source": [
    "Predict_tweets_main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(\"'American Crime Story' is expertly tackling the issue of fame https://t.co/x17guw5Ycq https://t.co/Z8OU0whTrl\", 'education'), ('RT @MIB_India: Union Minister Shri @sarbanandsonwal &amp; Shri N Ramachandran hand over the flag of  SouthAsianGames at Closing ceremony #South…', 'business'), ('RT @MIB_India: Union Minister Shri @sarbanandsonwal &amp; Shri N Ramachandran hand over the flag of  SouthAsianGames at Closing ceremony #South…', 'business'), ('The Muses in Greek mythology, poetry, and literature, are the... https://t.co/EfbayNpQhI #concertfilms', 'medical'), ('RT @MIB_India: Union Minister Shri @sarbanandsonwal &amp; Shri N Ramachandran hand over the flag of  SouthAsianGames at Closing ceremony #South…', 'business'), ('Has Islamic State run out of cash? https://t.co/gdMerpWyMQ #Australia #business', 'ethnic'), ('RT @sunandavashisht: On JNU Protests @HarithaPusarla asks -Are they mere voices of dissent? Very well argued piece  https://t.co/LDhTC85HTH', 'labour'), (\"#Wisconsin #Milwaukee #Madison 'Day without Latinos and Immigrants' organizers plan protest against bills https://t.co/TOEoextovC\", 'legal'), ('RT @satellitehigh: lol uber just hired a lawyer that is known specifically as america’s most successful union-breaker\\n\\nDISRUPTION sure look…', 'labour'), ('RT @MIB_India: Union Minister Shri @sarbanandsonwal &amp; Shri N Ramachandran hand over the flag of  SouthAsianGames at Closing ceremony #South…', 'business'), ('Girls night out.#fitchicks https://t.co/qWxwUUFA6V', 'education'), ('@Ray_Styles that would be awesome! See you tonight!', 'legal'), ('join demonstration of IRCTCWorkers today 1:30pm at CO Office,IRCTC Statesman House, Bharakhamba Road, ND against  termination of 92workers.', 'labour'), ('RT @HomeAdore: M&amp;M House by StudioMK27 | https://t.co/OumERAZJz0\\nPlease RT #architecture #interiordesign https://t.co/JIvRZErxNN', 'labour'), ('@geraldmellor Stymying market forces #greaterfool', 'labour'), ('RT @mundyspeaks: Purdue staffer resigns after threat to pro-life students https://t.co/zveNI0Qekc via @washtimes', 'education'), (\"RT @SirThomasWynne: @dodona777 \\n\\n🚫 LNP GOVT 🚫\\n\\nWHY WON'T THE LNP TOUCH NEGATIVE GEARING?\\n\\nSIMPLE - THEY WOULD LOSE A FORTUNE!\\n\\n#auspol http…\", 'business'), ('15:16 Fredericks Ct, Portland - Non Structure safe (one appliance, CFA district 4)  https://t.co/MHfj2zy8fp', 'legal'), ('RT @pharmasean: If someone asks \"why is there BBQ sauce in the bathroom\" &amp; u say \"oh I left it there after I took a bath\" u didnt really an…', 'labour'), ('RT @SamanthaCartel: #RETWEET NEED SOME NEW FOLLOWERS FROM THE #TityFollowTrain?\\n\\nYou have to be following my Bro @BoricuaTooDope!\\n\\nIm check…', 'legal')]\n"
     ]
    }
   ],
   "source": [
    "Predict_tweets_main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Issues Related to Labeling Tweets Based on GSR\n",
    "\n",
    "The predictions can be biased towards the training data set. Since the model is trained on words extracted from the training text it is likely to predict tweets which has similar words falling into that class. However, there can be situations where tweets describe a content which is relevant but having words out of the training corpus. \n",
    "Another issue is that the tweets which contain general context are predicted using web articles. Web articles considered are regarding certain events occurred. Eg: protest, rally etc. They are grouped to different population groups based on the people or the community who are related to the event. Eg: An article regarding a protest about medical issues conducted by doctors and medical staff will be labeled under “medical”. An article regarding a protest about medical issues conducted by people around the area or public will be labeled “general”. Since it is the addressing the general community.\n",
    "The general content in a tweet can be informative or not informative (“just general content”). Considering tweet terms related to an event might not be enough to categorize it into a population group. Additionally the tweet should be analyzed to identify the people related to it. A text can be regarding a protest. However, that text falls under a population group based on the people who handled it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternative method in building a frequency hash. Weigh the features based on the ocuurance of the words within the whole corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.feature import HashingTF, IDF\n",
    "htf = HashingTF(50000)\n",
    "\n",
    "def get_tfidf_data(label_features):\n",
    "    \n",
    "    labels = label_features.map(lambda doc: doc[\"populationGroup\"])\n",
    "    #htf = HashingTF(50000)\n",
    "    tf = htf.transform(label_features.map(lambda doc: doc[\"article\"]))\n",
    "       \n",
    "    idf = IDF().fit(tf)\n",
    "    tfidf = idf.transform(tf)\n",
    "    \n",
    "    #Combine using zip\n",
    "    data_set_hashed = labels.zip(tfidf).map(lambda x: LabeledPoint(x[0], x[1]))\n",
    "    \n",
    "    return data_set_hashed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main_tdif():\n",
    "    \n",
    "    data = load_gsr_articles()\n",
    "    data_paired = upsample_minority(data)\n",
    "    #data_paired = downsample_majority(data)\n",
    "    data_cleaned = tokenize_articles(data_paired)\n",
    "    #print(data_cleaned.take(2))\n",
    "    \n",
    "    #### method 1 ####\n",
    "    train_twitter_data, test_twitter_data = labeled_twitter_data.randomSplit([0.8, 0.2])    #split training and test data\n",
    "    train_set = data_cleaned.union(train_twitter_data)   #combine gsr and tweets\n",
    "    \n",
    "    train_data = get_tfidf_data(train_set)\n",
    "    test_data =  get_tfidf_data(test_twitter_data)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #### method 2 ####\n",
    "    #train_data=get_tfidf_data(data_cleaned)   #only gsr data as training set\n",
    "    #test_data = get_tfidf_data(labeled_twitter_data)   #only tweets as test set\n",
    "\n",
    "   \n",
    "    #### method 3 ####\n",
    "    #data_set =  get_tfidf_data(data_cleaned)\n",
    "    #train_data, test_data = data_set.randomSplit([0.8, 0.2])\n",
    "             \n",
    "    #apply hashed test and training data to the model\n",
    "    prediction_label = predict_tweets(train_data, test_data)\n",
    "    \n",
    "    metrics = get_model_metrics(prediction_label)\n",
    "    \n",
    "    confusion_matrix = get_confusionMatrix(metrics)\n",
    "    print(confusion_matrix)\n",
    "\n",
    "    print(\"\\n Summary Statistics for the Overall Model \\n\")\n",
    "    accuracy = 1.0 * prediction_label.filter(lambda result_line: result_line[0] == result_line[1]).count() / test_data.count()\n",
    "    print(\"Accuracy of model = %0.2f\" %accuracy)\n",
    "    \n",
    "    precision = metrics.precision()\n",
    "    recall = metrics.recall()\n",
    "    f1Score = metrics.fMeasure()\n",
    "    print(\"Precision = %s\" % precision)\n",
    "    print(\"Recall = %s\" % recall)\n",
    "    print(\"F1 Score = %s\" % f1Score)   \n",
    "    \n",
    "    labels = test_data.map(lambda lp: lp.label).distinct().collect()\n",
    "    print(\"\\n Summary Statistics for Each Tested Class \\n\")\n",
    "    for label in sorted(labels):\n",
    "        print(\"Class %s precision = %s\" % (rename_label(label), metrics.precision(label)))\n",
    "        print(\"Class %s recall = %s\" % ((rename_label(label), metrics.recall(label))))\n",
    "        print(\"Class %s F1 Measure = %s\" % ((rename_label(label), metrics.fMeasure(label, beta=1.0))))\n",
    "        print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  8.   4.   0.   5.   0.   1.   1.   0.]\n",
      " [  4.   8.   0.   0.   2.   2.   3.   3.]\n",
      " [  2.   2.   6.   2.   0.   1.   1.   6.]\n",
      " [  2.   5.   0.   9.   1.   0.   0.   5.]\n",
      " [  1.   5.   2.   0.   7.   1.   0.   3.]\n",
      " [  2.   8.   1.   1.   0.   6.   0.   1.]\n",
      " [  1.   7.   0.   0.   2.   0.  10.   0.]\n",
      " [  2.   2.   1.   2.   0.   0.   0.   9.]]\n",
      "\n",
      " Summary Statistics for the Overall Model \n",
      "\n",
      "Accuracy of model = 0.40\n",
      "Precision = 0.4012738853503185\n",
      "Recall = 0.4012738853503185\n",
      "F1 Score = 0.4012738853503185\n",
      "\n",
      " Summary Statistics for Each Tested Class \n",
      "\n",
      "Class education precision = 0.36363636363636365\n",
      "Class education recall = 0.42105263157894735\n",
      "Class education F1 Measure = 0.3902439024390244\n",
      "\n",
      "\n",
      "Class general precision = 0.1951219512195122\n",
      "Class general recall = 0.36363636363636365\n",
      "Class general F1 Measure = 0.25396825396825395\n",
      "\n",
      "\n",
      "Class business precision = 0.6\n",
      "Class business recall = 0.3\n",
      "Class business F1 Measure = 0.4\n",
      "\n",
      "\n",
      "Class ethnic precision = 0.47368421052631576\n",
      "Class ethnic recall = 0.4090909090909091\n",
      "Class ethnic F1 Measure = 0.43902439024390244\n",
      "\n",
      "\n",
      "Class medical precision = 0.5833333333333334\n",
      "Class medical recall = 0.3684210526315789\n",
      "Class medical F1 Measure = 0.4516129032258065\n",
      "\n",
      "\n",
      "Class religious precision = 0.5454545454545454\n",
      "Class religious recall = 0.3157894736842105\n",
      "Class religious F1 Measure = 0.39999999999999997\n",
      "\n",
      "\n",
      "Class agricultural precision = 0.6666666666666666\n",
      "Class agricultural recall = 0.5\n",
      "Class agricultural F1 Measure = 0.5714285714285715\n",
      "\n",
      "\n",
      "Class labour precision = 0.3333333333333333\n",
      "Class labour recall = 0.5625\n",
      "Class labour F1 Measure = 0.4186046511627907\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main_tdif()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main_tdif_test():\n",
    "    \n",
    "    data = load_gsr_articles()\n",
    "    data_paired = upsample_minority(data)\n",
    "    #data_paired = downsample_majority(data)\n",
    "    data_cleaned = tokenize_articles(data_paired)\n",
    "    \n",
    "    #### method 1 ####\n",
    "    data_set = data_cleaned.union(labeled_twitter_data)   #combine gsr and tweets\n",
    "    train_data = get_tfidf_data(data_set)\n",
    "\n",
    "    \n",
    "    df = get_twitter_data(1)\n",
    "    #df = get_data_bydate()\n",
    "    tweet_body = extract_tweet_body(df)\n",
    "    twitter_data = extract_tweet_features(tweet_body)\n",
    "        \n",
    "    test_data = get_tfidf_data(twitter_data)\n",
    "    \n",
    "    predictions = predict_tweets(train_data, test_data)\n",
    "    indexed_answer = get_predictions(predictions)\n",
    "        \n",
    "    joined_ans = display(tweet_body,indexed_answer)\n",
    "    print(joined_ans.take(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(\"@pnfinn @RLW_Mole @fitbit If Moley needed two hands he wouldn't be a journo.....\", 'labour'), (\"RT @JohnCleese: We're holding auditions and are stunned by just how many really good, funny Aussie performers there are.The FT tour opens A…\", 'general'), ('Looks like Sarah.. got Busteed. https://t.co/1j3vOmGT7O https://t.co/81D5G9DGTc', 'agricultural'), ('RT @TooSexist: How unfortunate... http://t.co/0QDzYwLcBu', 'agricultural'), (\"@msmaryandes I don't fully understand it myself, but basically the government pays for the bulk of most treatments, but some costs get thru.\", 'general'), ('RT @MaryJeanAdams: Prudence has 3 months to find a husband... Willing Love #99cents #Romance https://t.co/FRvkFET7Bb', 'education'), ('RT @dick_nixon: If only Bush could get his hands on the Glengarry Highlands leads.', 'business'), ('RT @StopShenhua: \"If mining damages the water supplies, there\\'ll be no vote, &amp; no election, that can help us\" #auspol #shenhua @nocsg https…', 'general'), ('RT @muniqui19: The @FBI said the #BPP free breakfast program was a threat. \\nFeeding ppl for free got them compared to the #KKK https://t.co…', 'business'), ('Hi, I just entered to Win a Win an Apple Watch Sport! Enter now for your chance!  https://t.co/oXzOsHlAyn', 'education'), ('RT @AliAbunimah: For Clinton and the progressive establishment that supports her, the violence imposed on Palestinians does not exist https…', 'agricultural'), ('\"I\\'ll play it first and tell you what it is later.\" - Miles Davis', 'general'), ('RT @davehardingham: Cherie facing corruption probe threat over £420,000 deal with MALDIVES despot https://t.co/1gkffLFKfs', 'labour'), ('Prosecutors Set to Indict Suspect in Bitcoin Mine Stabbing #Bitcoinsallday #Bitcoin https://t.co/FIljxifmDj via @CoinDesk', 'business'), ('RT @spnsides: Retweet if you want to gain just follow everyone who retweets this and follow back who ever follows you. 🔑❤️', 'labour'), ('@FarbsMcFarbs haha I\\'m just sick of this rebuttle. \"Time = money\" discounts a lot of reason why people do anything.', 'medical'), (\"BBC News - Vatican finance boss George Pell taunted over 'cowardice' https://t.co/1QAfIZZto0\", 'business'), ('Advanced Human [Feb 2016 Techno Chart] @beatport \\nhttps://t.co/xYMJrgdfPk\\nwith @PeterVanHoesen on the #1 spot this month.', 'general'), ('Before the next group of chosen ones is heading to Paris this year, enjoy a recap of \"Australian Designers... https://t.co/LUvOWY7Rcd', 'business'), ('@Toncahh @MythSolomoneK yeah fire up', 'religious')]\n"
     ]
    }
   ],
   "source": [
    "main_tdif_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This labeling is needed only if NB binary classification is considered\n",
    "#label classes for Naive Bayse considering education and all others\n",
    "def lable_class_edu(item_pop):\n",
    "    if item_pop.lower() == \"education\":\n",
    "        item_pop = 1\n",
    "    else:\n",
    "        item_pop = 2\n",
    "    return item_pop\n",
    "\n",
    "#label classes for Naive Bayse considering general population and all others\n",
    "def lable_class_gen(item_pop):\n",
    "    if \"general\" in item_pop.lower():\n",
    "        item_pop = 1\n",
    "    else:\n",
    "        item_pop = 2\n",
    "    return item_pop\n",
    "\n",
    "#label classes for Naive Bayse considering legal and all others\n",
    "def lable_class_leg(item_pop):\n",
    "    if \"legal\" in item_pop.lower():\n",
    "        item_pop = 1\n",
    "    else:\n",
    "        item_pop = 2\n",
    "    return item_pop\n",
    "\n",
    "#label classes for Naive Bayse considering ethnic and all others\n",
    "def lable_class_eth(item_pop):\n",
    "    if \"ethnic\" in pop_item.lower():\n",
    "        item_pop = 1\n",
    "    else:\n",
    "        item_pop = 2\n",
    "    return item_pop\n",
    "\n",
    "#label classes for Naive Bayse considering religious and all others\n",
    "def lable_class_reli(item_pop):\n",
    "    if \"religious\" in item_pop.lower():\n",
    "        item_pop = 1\n",
    "    else:\n",
    "        item_pop = 2\n",
    "    return item_pop\n",
    "\n",
    "#label classes for Naive Bayse considering media and all others\n",
    "def lable_class_reli(item_pop):\n",
    "    if \"media\" in item_pop.lower():\n",
    "        item_pop = 1\n",
    "    else:\n",
    "        item_pop = 2\n",
    "    return item_pop\n",
    "\n",
    "#label classes for Naive Bayse considering media and all others\n",
    "def lable_class_reli(item_pop):\n",
    "    if re.compile('agricul[tural|ture]').match(item_pop.lower()):\n",
    "        item_pop = 1\n",
    "    else:\n",
    "        item_pop = 2\n",
    "    return item_pop\n",
    "\n",
    "#label classes for Naive Bayse considering media and all others\n",
    "def lable_class_labour(item_pop):\n",
    "    if re.compile('lab[or|our]').match(item_pop.lower()):\n",
    "        item_pop = 1\n",
    "    else:\n",
    "        item_pop = 2\n",
    "    return item_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "\n",
    "def NaiveBayes_Binary_main():\n",
    "    \n",
    "    data = load_gsr_articles()\n",
    "    data_cleaned = tokenize_articles_binary(data)\n",
    "    hashed_data = transform_data(data_cleaned)\n",
    "    \n",
    "    train_hashed, test_hashed = hashed_data.randomSplit([0.8, 0.2])\n",
    "    \n",
    "    NB_model = train_model(train_hashed)\n",
    "    #model.save(sc, \"ModelPath\")\n",
    "    #sameModel = NaiveBayesModel.load(sc, \"ModelPath\")\n",
    "\n",
    "    predictionAndLabel = test_hashed.map(lambda p : (float(NB_model.predict(p.features)), p.label))\n",
    "\n",
    "    #accuracy = 1.0 * predictionAndLabel.filter(lambda result_line: result_line[0] == result_line[1]).count() / test_hashed.count()\n",
    "    #print(\"Accuracy of model = %0.2f\" %accuracy)\n",
    "    \n",
    "    #print(predictionAndLabel.take(5))\n",
    "    metrics = BinaryClassificationMetrics(predictionAndLabel)\n",
    "    \n",
    "    print(\"Area under PR = %s\" % metrics.areaUnderPR)\n",
    "    print(\"Area under ROC = %s\" % metrics.areaUnderROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

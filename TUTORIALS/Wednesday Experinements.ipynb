{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "frequency = {}\n",
    "import string\n",
    "frequency = {}\n",
    "frequency1= {}\n",
    "document_text = open('test.txt', 'r')\n",
    "#document_text1 = open('xtest.txt', 'r')\n",
    "#document_text = \"The boy is going\"\n",
    "text_string = document_text.read().lower()\n",
    "#text_string1 = document_text1.read().lower()\n",
    "\n",
    "#clean all Url from texts.\n",
    "#result = re.sub(r\"http\\S+\", \" \",  text_string)\n",
    "#result = re.sub(r\"[^A-Za-z0-9]+\", \" \",  text_string)\n",
    "\n",
    "result = re.sub(r\"http\\S+\", \" \",  text_string)\n",
    "result1 = re.sub(r\"\\W+\", \" \", result )\n",
    "#result = re.sub(r\"^https?:\\/\\/.*[\\r\\n]*\", \" \",  result1)\n",
    "\n",
    "#result1 = re.sub(r\"\\W+\", \" \",  text_string1)\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "word_tokens = word_tokenize(result)\n",
    "\n",
    "filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "#filtered_sentence1 = [x for x in word_tokens1 if not x in stop_words]\n",
    "\n",
    "filtered_sentence = []\n",
    "\n",
    "for w in word_tokens:\n",
    "    if w not in stop_words:\n",
    "        filtered_sentence.append(w)\n",
    "        \n",
    "#stx =   re.sub(r\"co\", \" \", filtered_sentence)      \n",
    "str1 = ' '.join(filtered_sentence)\n",
    "\n",
    "match_pattern = re.findall(r'\\b[a-z]{3,15}\\b', str1)\n",
    "#match_pattern1 = re.findall(r'\\b[a-z]{3,15}\\b', str2)\n",
    "\n",
    "for word in match_pattern:\n",
    "    count = frequency.get(word,0)\n",
    "    frequency[word] = count + 1\n",
    "    \n",
    "         \n",
    "frequency_list = frequency.keys()\n",
    " \n",
    "for words in frequency_list:\n",
    "    #print(words, frequency[words])\n",
    "    h =1\n",
    "#print(str1)\n",
    "\n",
    "df = pd.DataFrame(data={'A': frequency})\n",
    "#df.sort( ascending=True)\n",
    "df1 = df.nlargest(20, 'A')\n",
    "df1\n",
    "type(filtered_sentence)\n",
    "#result1\n",
    "#str1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ttp import ttp\n",
    "p = ttp.Parser()\n",
    "resultx = p.parse(result)\n",
    "resultx.reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['farmer', 'cooperatebusiness', '23daysforthalapathybday', 'currentsituation']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultx.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://github.com/edburnett/']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.urls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
